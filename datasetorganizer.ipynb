{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of Dataset_creation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "hz8Q4K6MAOZE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "import shutil\n",
        "import os\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cY1W8qrqAuFB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#mount google drive to access the stored data set and manipulate it\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ntGO3itD4Y_C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#path configuration\n",
        "parent_dir = '/content/gdrive/My Drive/assignment_dataset'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H7xvGxASAvOn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#get category folder list\n",
        "os.chdir(parent_dir)\n",
        "category_list = list(filter(lambda x: os.path.isdir(x), os.listdir()))\n",
        "for category in category_list:\n",
        "  print(category)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ozQ2EcX0AvLi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#create training,validation,testing directories\n",
        "data_set_dirs= ['train','valid','test']\n",
        "for dsdirs in data_set_dirs:\n",
        "  path = parent_dir + '/'+ dsdirs\n",
        "  os.mkdir( path,755 )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IJ0oFwHsAvHI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#define proportion of data\n",
        "train_prop = 0.6\n",
        "valid_prop = test_prop = (1-train_prop)/2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LH-H3OQQAu0Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#function to split data of each category into trainning, validation and testing set\n",
        "def create_dataset():\n",
        "  for ii,cat in enumerate(category_list):    \n",
        "    src_path = parent_dir + '/' + cat\n",
        "    dest_dir1 = parent_dir+'/train/'+str(ii)\n",
        "    dest_dir2 = parent_dir+'/valid/'+str(ii)\n",
        "    dest_dir3 = parent_dir+'/test/'+str(ii)\n",
        "    \n",
        "    dest_dirs_list = [dest_dir1,dest_dir2,dest_dir3]\n",
        "    for dirs in dest_dirs_list:\n",
        "      os.mkdir(dirs,755 )\n",
        "    \n",
        "    #get files' names list from respective directories\n",
        "    os.chdir(src_path)\n",
        "    files = [f for f in os.listdir() if os.path.isfile(f)]\n",
        "    \n",
        "    #get training, testing and validation files count\n",
        "    train_count = math.ceil(train_prop*len(files))\n",
        "    valid_count = int((len(files)-train_count)/2)\n",
        "    test_count = valid_count\n",
        "    \n",
        "    #get files to segragate for train,test and validation data set\n",
        "    train_data_list = files[0: train_count]\n",
        "    valid_data_list = files[train_count+1:train_count+1+valid_count]  \n",
        "    test_data_list =  files[train_count+valid_count:]\n",
        "       \n",
        "  \n",
        "    for train_data in train_data_list:\n",
        "      train_path = src_path + '/' + train_data\n",
        "      shutil.copy(train_path,dest_dir1)\n",
        "    \n",
        "    for valid_data in valid_data_list:\n",
        "      valid_path = src_path + '/' + valid_data\n",
        "      shutil.copy(valid_path,dest_dir2)\n",
        "    \n",
        "    for test_data in test_data_list:\n",
        "      test_path = src_path + '/' + test_data\n",
        "      shutil.copy(test_path,dest_dir3)    \n",
        "    \n",
        "create_dataset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "giZiZeI-Auly",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#save category data as dictionary in a json file\n",
        "cat_data = {}\n",
        "for ix,cat in enumerate(category_list):\n",
        "  cat_data[ix] = cat\n",
        "with open('/content/gdrive/My Drive/assignment_dataset/cat_data.json', 'w') as outfile:  \n",
        "    json.dump(cat_data , outfile)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}